{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book : Python Data Science Handbook\n",
    "## Chapter 3 - Data Manipulation with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    " Pandas is a newer package built on top of NumPy, and provides an efficient implementation of a DataFrame. DataFrames are essentially multidimensional arrays with attached row and column labels, and often with heterogeneous types and/or missing data. As well as offering a convenient storage interface for labeled data, Pandas implements a number of powerful data operations familiar to users of both database frameworks and spreadsheet programs.\n",
    " \n",
    "Pandas, and in particular its Series and DataFrame objects, builds on the NumPy array structure and provides efficient access of \"data munging\" tasks that occupy much of a data scientist's time.\n",
    "\n",
    "For example, to display all the contents of the pandas namespace, you can type\n",
    "\n",
    "In [3]: pd.<TAB>\n",
    "And to display Pandas's built-in documentation, you can use this:\n",
    "\n",
    "In [4]: pd?\n",
    "\n",
    "More detailed documentation, along with tutorials and other resources, can be found at http://pandas.pydata.org/.\n",
    "\n",
    "\n",
    "At the very basic level, Pandas objects can be thought of as enhanced versions of NumPy structured arrays in which the rows and columns are identified with labels rather than simple integer indices. \n",
    "\n",
    "Pandas data structures: \n",
    "* Series\n",
    "* DataFrame\n",
    "* Index.\n",
    "\n",
    "## The Pandas Series Object\n",
    "A Pandas Series is a one-dimensional array of indexed data. It can be created from a list or array.\n",
    "\n",
    "The Series wraps \n",
    "* a sequence of values, The values are simply a familiar NumPy array\n",
    "* a sequence of indices, \n",
    "\n",
    "which we can access with the values and index attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.25\n",
      "1    0.50\n",
      "2    0.75\n",
      "3    1.00\n",
      "dtype: float64\n",
      "[0.25 0.5  0.75 1.  ]\n",
      "RangeIndex(start=0, stop=4, step=1)\n",
      "0.5\n",
      "3    1.0\n",
      "1    0.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "print(data)\n",
    "print(data.values)\n",
    "print(data.index)\n",
    "\n",
    "# We can access series elements just like indexing np arrays\n",
    "print(data[1])\n",
    "print(data[::-2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series as generalized NumPy array\n",
    "Series object is basically interchangeable with a one-dimensional NumPy array. The essential difference is the presence of the index: while the Numpy Array has an implicitly defined integer index used to access the values, the Pandas Series has an explicitly defined index associated with the values.\n",
    "\n",
    "This explicit index definition gives the Series object additional capabilities. For example, the index need not be an integer, but can consist of values of any desired type. For example, if we wish, we can use strings as an index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     5.0\n",
      "b     4.0\n",
      "c     3.0\n",
      "d     2.1\n",
      "e    10.0\n",
      "dtype: float64\n",
      "\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([5, 4, 3, 2.1, 10],\n",
    "                index = ['a','b','c','d','e'])# in array indexes will always be an integer, but in series it can be of\n",
    "                                              # any type\n",
    "print(data)\n",
    "print()\n",
    "print(data['b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series as specialized dictionary\n",
    "\n",
    "--> A dictionary is a structure that maps arbitrary keys to a set of arbitrary values, \n",
    "\n",
    "--> And a Series is a structure which maps typed keys to a set of typed values. \n",
    "\n",
    "This typing is important: just as the type-specific compiled code behind a NumPy array makes it more efficient than a Python list for certain operations, the type information of a Pandas Series makes it much more efficient than Python dictionaries for certain operations.\n",
    "\n",
    "The Series-as-dictionary analogy can be made even more clear by constructing a Series object directly from a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California    38332521\n",
      "Texas         26448193\n",
      "New York      19651127\n",
      "Florida       19552860\n",
      "Illinois      12882135\n",
      "dtype: int64\n",
      "\n",
      "California    38332521\n",
      "Texas         26448193\n",
      "New York      19651127\n",
      "Florida       19552860\n",
      "Illinois      12882135\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "population = pd.Series(population_dict)\n",
    "print(population)\n",
    "print()\n",
    "print(population['California':'Illinois'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Series object\n",
    "We've already seen a few ways of constructing a Pandas Series from scratch; all of them are some version of the following:\n",
    "\n",
    "> pd.Series(data, index=index)\n",
    "\n",
    "where index is an optional argument, and data can be one of many entities.\n",
    "\n",
    "For example, data can be a list or NumPy array, in which case index defaults to an integer sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    5\n",
      "130    5\n",
      "160    5\n",
      "190    5\n",
      "dtype: int64\n",
      "a    1.0\n",
      "b    2.5\n",
      "c    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#data can be a scalar, which is repeated to fill the specified index:\n",
    "print(pd.Series(5, index= np.arange(100,200,30)))\n",
    "\n",
    "#Here, the Series is populated only with the explicitly identified keys. \n",
    " #And sorted in the order of the indexes provided\n",
    "print(pd.Series({'a':1,'d':2,'b':2.5,'c':3.0}, index = ['a','b','c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pandas DataFrame Object\n",
    "\n",
    "### DataFrame as a generalized NumPy array\n",
    "\n",
    "If a Series is an analog of a one-dimensional array with flexible indices, a DataFrame is an analog of a two-dimensional array with both flexible row indices and flexible column names. Just as you might think of a two-dimensional array as an ordered sequence of aligned one-dimensional columns, you can think of a DataFrame as a sequence of aligned Series objects. Here, by \"aligned\" we mean that they share the same index.\n",
    "\n",
    "### DataFrame as specialized dictionary\n",
    "Similarly, we can also think of a DataFrame as a specialization of a dictionary. Where a dictionary maps a key to a value, a DataFrame maps a column name to a Series of column data. For example, asking for the 'area' attribute.\n",
    "returns the Series object containing the areas we saw earlier.\n",
    "\n",
    "### From a NumPy structured array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              area  location\n",
      "California  423967         1\n",
      "Florida     170312         4\n",
      "Illinois    149995         5\n",
      "New York    141297         3\n",
      "Texas       695662         2\n",
      "\n",
      "California    423967\n",
      "Florida       170312\n",
      "Illinois      149995\n",
      "New York      141297\n",
      "Texas         695662\n",
      "Name: area, dtype: int64\n",
      "423967\n",
      "Index(['California', 'Florida', 'Illinois', 'New York', 'Texas'], dtype='object')\n",
      "Index(['area', 'location'], dtype='object')\n",
      "[[423967      1]\n",
      " [170312      4]\n",
      " [149995      5]\n",
      " [141297      3]\n",
      " [695662      2]]\n",
      "(5, 2)\n",
      "            population\n",
      "California    38332521\n",
      "Texas         26448193\n",
      "New York      19651127\n",
      "Florida       19552860\n",
      "Illinois      12882135\n",
      "     a  b    c\n",
      "0  1.0  2  NaN\n",
      "1  NaN  3  4.0\n",
      "   A    B\n",
      "0  0  0.0\n",
      "1  0  0.0\n",
      "2  0  0.0\n"
     ]
    }
   ],
   "source": [
    "# Creating two series\n",
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "#print(area)\n",
    "#print()\n",
    "locn_dict = {'Florida': 4, 'California': 1, 'Texas': 2, 'New York': 3,\n",
    "              'Illinois': 5}\n",
    "location = pd.Series(locn_dict)\n",
    "#print(location)\n",
    "\n",
    "# creating a dataframe from above series using dictionary\n",
    "states_data = pd.DataFrame( { 'area' : area, 'location' : location})\n",
    "print(states_data)\n",
    "\n",
    "print()\n",
    "print(states_data['area'])\n",
    "print(states_data['area']['California'])\n",
    "\n",
    "# Attributes of a dataframe object\n",
    "print(states_data.index)\n",
    "print(states_data.columns)\n",
    "print(states_data.values)\n",
    "print(states_data.shape)\n",
    "\n",
    "# Different ways to construct dataframe objects\n",
    "\n",
    "#1. a single column dataframe can be created from a single series\n",
    "print(pd.DataFrame(population, columns=['population']))\n",
    "\n",
    "#2.\n",
    "# From a dictionary of Series objects\n",
    "# Using a dictionary, where keys are names of columns, and values are series (columns)\n",
    "# We have already created this type above\n",
    "\n",
    "#3. Using list of dictionaries, where each dictionary are rows.\n",
    "# for missing keys in different dictionaries will be automatically filled with NAs\n",
    "print(pd.DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}]))\n",
    "\n",
    "#4.\n",
    "# from numpy arrray\n",
    "A = np.zeros(3, dtype=[('A', 'i8'), ('B', 'f8')])\n",
    "print(pd.DataFrame(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pandas Index Object\n",
    "\n",
    "We have seen here that both the Series and DataFrame objects contain an explicit index that lets you reference and modify data. It can be thought of as\n",
    "\n",
    "* an immutable array \n",
    "* an ordered set (technically a multi-set, as Index objects may contain repeated values). \n",
    "\n",
    "Those views have some interesting consequences in the operations available on Index objects. As a simple example, let's construct an Index from a list of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([2, 3, 5, 7, 11], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "ind = pd.Index([2, 3, 5, 7, 11])\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([3, 7], dtype='int64')\n",
      "\n",
      "Int64Index([3, 5, 7], dtype='int64')\n",
      "Int64Index([1, 2, 3, 5, 7, 9, 11], dtype='int64')\n",
      "Int64Index([1, 2, 9, 11], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# we can access index just like an array\n",
    "print(ind[1:6:2])\n",
    "print()\n",
    "# One difference between Index objects and NumPy arrays is that indices are immutable–that is\n",
    "# they cannot be modified via the normal mean\n",
    "# ind[1] = 0 # is not possible\n",
    "\n",
    "indA = pd.Index([1, 3, 5, 7, 9])\n",
    "indB = pd.Index([2, 3, 5, 7, 11])\n",
    "print(indA & indB) #intersection\n",
    "print(indA | indB) #union\n",
    "print(indA ^ indB) #symmetric difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection in Series\n",
    "As we have seen previously, a Series object acts in many ways like a one-dimensional NumPy array, and in many ways like a standard Python dictionary. If we keep these two overlapping analogies in mind, it will help us to understand the patterns of data indexing and selection in these arrays.\n",
    "\n",
    "### Series as Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0.25\n",
      "b    0.50\n",
      "c    0.75\n",
      "d    1.00\n",
      "dtype: float64\n",
      "\n",
      "0.25\n",
      "True\n",
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "<zip object at 0x7f50583c8b40>\n",
      "[('a', 0.25), ('b', 0.5), ('c', 0.75), ('d', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "# We can also use dictionary-like Python expressions and methods to examine the keys/indices and values:\n",
    "print(data['a'])\n",
    "print('a' in data)\n",
    "print(data.keys())\n",
    "\n",
    "print(data.items())\n",
    "print(list(data.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series as one-dimensional array\n",
    " Series builds on this dictionary-like interface and provides array-style item selection via the same basic mechanisms as NumPy arrays – that is, slices, masking, and fancy indexing. Examples of these are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing by explicit index\n",
    "print(data['a':'c'])\n",
    "# Slicing by implicit index\n",
    "print(data[0:3])\n",
    "# Masking\n",
    "print(data[ (data >= 0.25) & (data <= .5)])\n",
    "#fancy indexing\n",
    "print(data[['a','e']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexers: loc, iloc, and ix\n",
    "These slicing and indexing conventions can be a source of confusion. For example, if your Series has an explicit integer index, an indexing operation such as data[1] will use the explicit indices, while a slicing operation like data[1:3] will use the implicit Python-style index.\n",
    "\n",
    "Because of this potential confusion in the case of integer indexes, Pandas provides some special indexer attributes that explicitly expose certain indexing schemes. These are not functional methods, but attributes that expose a particular slicing interface to the data in the Series.\n",
    "\n",
    "I recommend using .loc and .iloc attributes to make code easier to read and understand, and to prevent subtle bugs due to the mixed indexing/slicing convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    a\n",
      "3    b\n",
      "5    c\n",
      "dtype: object\n",
      "a\n",
      "3    b\n",
      "5    c\n",
      "dtype: object\n",
      "a\n",
      "1    a\n",
      "3    b\n",
      "dtype: object\n",
      "b\n",
      "3    b\n",
      "5    c\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])\n",
    "print(data)\n",
    "# explicit index when indexing\n",
    "print(data[1])\n",
    "# implicit index when slicing\n",
    "print(data[1:3])\n",
    "\n",
    "# .loc attribute allows indexing and slicing that always reference explicit index \n",
    "print(data.loc[1])\n",
    "print(data.loc[1:3])\n",
    "\n",
    "# The iloc attribute allows indexing and slicing that always references the implicit Python-style index:\n",
    "print(data.iloc[1])\n",
    "print(data.iloc[1:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection in DataFrame\n",
    "### Dataframe as a Dictionary\n",
    "\n",
    "* When we index a dataframe with a single element, then it returns a series.\n",
    "* When we slice a dataframe, one or more columns or rows, it returns a datafame.\n",
    "* when we provide a single column as string, it returns a series.\n",
    "* when we provide a list for column selection, it returns a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California    423967\n",
      "Texas         695662\n",
      "New York      141297\n",
      "Florida       170312\n",
      "Illinois      149995\n",
      "Name: area, dtype: int64\n",
      "California    423967\n",
      "Texas         695662\n",
      "New York      141297\n",
      "Florida       170312\n",
      "Illinois      149995\n",
      "Name: area, dtype: int64\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
    "                  'New York': 141297, 'Florida': 170312,\n",
    "                  'Illinois': 149995})\n",
    "pop = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                 'New York': 19651127, 'Florida': 19552860,\n",
    "                 'Illinois': 12882135})\n",
    "data = pd.DataFrame({'area':area, 'pop':pop})\n",
    "\n",
    "print(data['area']) # returns a series\n",
    "print(data.area) # we can use attribute-style access with column names that are strings\n",
    "print(data.area is data['area'])\n",
    "\n",
    "# if the column names are not strings, or if the column names conflict with methods of the DataFrame,\n",
    "# this attribute-style access is not possible.\n",
    "print(data.pop is data['pop']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame as two-dimensional array\n",
    " Using the iloc indexer, we can index the underlying array as if it is a simple NumPy array (using the implicit Python-style index), but the DataFrame index and column labels are maintained in the result.\n",
    " \n",
    " Similarly, using the loc indexer we can index the underlying data in an array-like style but using the explicit index and column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              area       pop\n",
      "California  423967  38332521\n",
      "Texas       695662  26448193\n",
      "New York    141297  19651127\n",
      "Florida     170312  19552860\n",
      "Illinois    149995  12882135\n",
      "[[  423967 38332521]\n",
      " [  695662 26448193]\n",
      " [  141297 19651127]\n",
      " [  170312 19552860]\n",
      " [  149995 12882135]]\n",
      "      California     Texas  New York   Florida  Illinois\n",
      "area      423967    695662    141297    170312    149995\n",
      "pop     38332521  26448193  19651127  19552860  12882135\n",
      "              area       pop\n",
      "California  423967  38332521\n",
      "Texas       695662  26448193\n",
      "New York    141297  19651127\n",
      "              area\n",
      "California  423967\n",
      "Texas       695662\n",
      "New York    141297\n",
      "Florida     170312\n",
      "                 pop    area\n",
      "California  38332521  423967\n",
      "Texas       26448193  695662\n",
      "New York    19651127  141297\n",
      "Florida     19552860  170312\n",
      "Illinois    12882135  149995\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(data.values) #returns numpy array\n",
    "print(data.T)  # Transpose of data, rows becomes columns and columns becomes columns\n",
    "\n",
    "#Slicing dataframe as numpy array, implicit indexing\n",
    "print(data.iloc[:3, :2])\n",
    "\n",
    "#Slicing dataframe using explicit indexing\n",
    "print(data.loc[:'Florida', :'area'])\n",
    "print(data.loc[data['pop'] > 10000, ['pop', 'area']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating on pandas Dataframe\n",
    "One of the essential pieces of NumPy is the ability to perform quick element-wise operations. Pandas inherits much of this functionality from NumPy, and the ufuncs that we introduced in Computation on NumPy Arrays: Universal Functions are key to this.\n",
    "\n",
    "Pandas includes a couple useful twists, however: \n",
    "* For unary operations like negation and trigonometric functions, these ufuncs will preserve index and column labels in the output, \n",
    "* And for binary operations such as addition and multiplication, Pandas will automatically align indices when passing the objects to the ufunc. \n",
    "\n",
    "This means that keeping the context of data and combining data from different sources–both potentially error-prone tasks with raw NumPy arrays–become essentially foolproof ones with Pandas.\n",
    "\n",
    "### Ufuncs: Index Preservation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6\n",
      "1    3\n",
      "2    7\n",
      "3    4\n",
      "4    6\n",
      "dtype: int64\n",
      "\n",
      "   a  b  c  d\n",
      "0  9  2  6  7\n",
      "1  4  3  7  7\n",
      "2  2  5  4  1\n",
      "\n",
      "0     403.428793\n",
      "1      20.085537\n",
      "2    1096.633158\n",
      "3      54.598150\n",
      "4     403.428793\n",
      "dtype: float64\n",
      "\n",
      "              a         b             c         d\n",
      "0  7.071068e-01  1.000000 -1.000000e+00 -0.707107\n",
      "1  1.224647e-16  0.707107 -7.071068e-01 -0.707107\n",
      "2  1.000000e+00 -0.707107  1.224647e-16  0.707107\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "ser = pd.Series(rng.randint(0,10,5))\n",
    "print(ser,end =\"\\n\\n\")\n",
    "\n",
    "df = pd.DataFrame(rng.randint(0,10,(3,4)), columns = ['a','b','c','d'])\n",
    "print(df,end =\"\\n\\n\")\n",
    "\n",
    "# Uniary operations using Ufuncs of numpy, it presernves the order of index and columns\n",
    "\n",
    "# Exponential of every element of the series\n",
    "print(np.exp(ser),end =\"\\n\\n\")\n",
    "\n",
    "# Element wise operation on dataframe\n",
    "print(np.sin(df * np.pi / 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UFuncs: Index Alignment\n",
    "For binary operations on two Series or DataFrame objects, Pandas will align indices in the process of performing the operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alaska        1723337\n",
      "Texas          695662\n",
      "California     423967\n",
      "Name: area, dtype: int64\n",
      "\n",
      "California    38332521\n",
      "Texas         26448193\n",
      "New York      19651127\n",
      "Name: population, dtype: int64\n",
      "\n",
      "Alaska             NaN\n",
      "California    0.011060\n",
      "New York           NaN\n",
      "Texas         0.026303\n",
      "dtype: float64\n",
      "\n",
      "0    NaN\n",
      "1    5.0\n",
      "2    9.0\n",
      "3    NaN\n",
      "dtype: float64\n",
      "0    2.0\n",
      "1    5.0\n",
      "2    9.0\n",
      "3    5.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Series\n",
    "area = pd.Series({'Alaska': 1723337, 'Texas': 695662,\n",
    "                  'California': 423967}, name='area')\n",
    "population = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                        'New York': 19651127}, name='population')\n",
    "print(area,end =\"\\n\\n\")\n",
    "print(population,end =\"\\n\\n\")\n",
    "\n",
    "# The resulting array contains the union of indices of the two input arrays\n",
    "print(area/population,end =\"\\n\\n\")  # Any item for which one or the other does not have an entry is marked with NaN, or \"Not a Number,\" \n",
    "                                    #  which is how Pandas marks missing data\n",
    "    \n",
    "## How to handle this missing values, if not desirable\n",
    "A = pd.Series([2, 4, 6], index=[0, 1, 2])\n",
    "B = pd.Series([1, 3, 5], index=[1, 2, 3])\n",
    "print(A + B) # As you see, index 3 doesnot have any value in A and B doesnot have any value for index 3.\n",
    "             # So 'NaN' are marked if any of the items corresponding to a single index doesnt have value.\n",
    "\n",
    "print(A.add(B, fill_value=0), end='\\n\\n')   # It fills 0, where the values are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b\n",
      "0  8  3\n",
      "1  8  2\n",
      "\n",
      "   a  b  c\n",
      "0  6  5  7\n",
      "1  8  4  0\n",
      "2  2  9  7\n",
      "\n",
      "      a    b   c\n",
      "0  14.0  8.0 NaN\n",
      "1  16.0  6.0 NaN\n",
      "2   NaN  NaN NaN\n",
      "\n",
      "0  a    8\n",
      "   b    3\n",
      "1  a    8\n",
      "   b    2\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "[8 3 8 2]\n",
      "MultiIndex(levels=[[0, 1], ['a', 'b']],\n",
      "           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n",
      "\n",
      "Average value of DF A:  5.25\n",
      "       a      b      c\n",
      "0  14.00   8.00  12.25\n",
      "1  16.00   6.00   5.25\n",
      "2   7.25  14.25  12.25\n"
     ]
    }
   ],
   "source": [
    "# Dataframe (Index Alignment)\n",
    "A = pd.DataFrame(rng.randint(0,10, (2,2)), columns =list('ab'))\n",
    "B = pd.DataFrame(rng.randint(0,10, (3,3)), columns =list('abc'))\n",
    "print(A,end='\\n\\n')\n",
    "print(B,end='\\n\\n')\n",
    "\n",
    "print(A+B,end='\\n\\n')\n",
    "\n",
    "print(A.stack())       # Melts data, bring row index and columns as multilevel index and put all the values in as single series/column\n",
    "print(type(A.stack()))\n",
    "print(A.stack().values)\n",
    "print(A.stack().index)\n",
    "print()\n",
    "\n",
    "fill = A.stack().mean() # computes mean of all values of df A\n",
    "print('Average value of DF A: ',fill)\n",
    "print(A.add(B, fill_value = fill))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ufuncs: Operations Between DataFrame and Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 4 3 7]\n",
      " [6 1 0 3]\n",
      " [7 1 2 0]]\n",
      "\n",
      "[7 4 3 7]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [-1 -3 -3 -4]\n",
      " [ 0 -3 -1 -7]]\n",
      "\n",
      "   p  q  r  s\n",
      "0  7  4  3  7\n",
      "1  6  1  0  3\n",
      "2  7  1  2  0\n",
      "\n",
      "p    7\n",
      "q    4\n",
      "r    3\n",
      "s    7\n",
      "Name: 0, dtype: int64\n",
      "\n",
      "   p  q  r  s\n",
      "0  7  4  3  7\n",
      "\n",
      "   p  q  r  s\n",
      "0  0  0  0  0\n",
      "1 -1 -3 -3 -4\n",
      "2  0 -3 -1 -7\n",
      "\n",
      "     p    q    r    s\n",
      "0  0.0  0.0  0.0  0.0\n",
      "1  NaN  NaN  NaN  NaN\n",
      "2  NaN  NaN  NaN  NaN\n",
      "\n",
      "   p  q  r  s\n",
      "0  0 -3 -4  0\n",
      "1  0 -5 -6 -3\n",
      "2  0 -6 -5 -7\n"
     ]
    }
   ],
   "source": [
    "#Numpy Array\n",
    "A = rng.randint(10, size=(3, 4))\n",
    "print(A, end='\\n\\n')\n",
    "print(A[0], end='\\n\\n')     # Selects first row\n",
    "print(A - A[0], end='\\n\\n') # Default, row wise operation\n",
    "\n",
    "# Dataframe\n",
    "A = pd.DataFrame(A, columns=['p','q','r','s'])\n",
    "print(A, end='\\n\\n')\n",
    "#print(A[0], end='\\n\\n')      # Selectes first column, for dataframe\n",
    "#print(A - A[0], end='\\n\\n')  # Default, row wise operation\n",
    "\n",
    "print(A.iloc[0], end='\\n\\n')       # Selectes first row as Series, \n",
    "print(A.iloc[0:1], end='\\n\\n')      # Selectes first row as dataframe\n",
    "\n",
    "# When we take difference of dataframe with series, the series broadcast.\n",
    "print(A - A.iloc[0], end='\\n\\n')  # Default, row wise operation\n",
    "\n",
    "# But when we take difference of dataframe with a single column dataframe (similar to a series but not a series)\n",
    "# Then it does not broadcast and do element wise operation and put missing if corresponding value is missing for same\n",
    "# indexes as we have seen previously\n",
    "print(A - A.iloc[0:1], end='\\n\\n')  # Default, row wise operation\n",
    "\n",
    "\n",
    "\n",
    "# for columnwise operation use the method instead of operator\n",
    "print(A.subtract(A['p'], axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   p  q  r  s\n",
      "0  7  4  3  7\n",
      "1  6  1  0  3\n",
      "2  7  1  2  0\n",
      "\n",
      "p    7\n",
      "r    3\n",
      "Name: 0, dtype: int64\n",
      "\n",
      "     p   q    r   s\n",
      "0  0.0 NaN  0.0 NaN\n",
      "1 -1.0 NaN -3.0 NaN\n",
      "2  0.0 NaN -1.0 NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Note that these DataFrame/Series operations, like the operations discussed above, will automatically\n",
    "# align indices between the two elements:\n",
    "print(A, end='\\n\\n')\n",
    "\n",
    "halfrow = A.iloc[0, ::2]\n",
    "print(halfrow, end='\\n\\n')\n",
    "\n",
    "print(A - halfrow) # Automatically aligne indicesm and brodcasted the series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data on Pandas\n",
    "Missingness in python represented by two ways:\n",
    "* Masking array, a different array than dataset marks missing value in the dataset.\n",
    "* Sentinel value, a value that represents missing value in the dataset itself. like np.nan, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### None: Pythonic missing data\n",
    "This dtype=object means that the best common type representation NumPy could infer for the  contents of the array is that they are Python objects. While this kind of object array is useful for some purposes, any operations on the data will be done at the Python level, with much more overhead than the typically fast operations seen for arrays with native types:\n",
    "\n",
    "In easy language, if we represent missing data with None object, then all the elements of array itself would become python object type. which will slow any operation on them for large arrays\n",
    "\n",
    "The use of Python objects in an array also means that if you perform aggregations like sum() or min() across an array with a None value, you will generally get an error:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 None 3 4] \n",
      "\n",
      "\n",
      "object \n",
      "\n",
      "\n",
      "dtype = object\n",
      "169 µs ± 4.55 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "dtype = int\n",
      "27 µs ± 4.74 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vals1 = np.array([1, None, 3, 4])\n",
    "print(vals1)\n",
    "print(vals1.dtype,'\\n\\n')\n",
    "\n",
    "for dtype in ['object', 'int']:\n",
    "    print(\"dtype =\", dtype)\n",
    "    %timeit np.arange(1E3, dtype=dtype).sum()\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN: Missing numerical data\n",
    "The other missing data representation, NaN (acronym for Not a Number), is different; it is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation:\n",
    "\n",
    "Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code. You should be aware that NaN is a bit like a data virus–it infects any other object it touches. Regardless of the operation, the result of arithmetic with NaN will be another NaN\n",
    "\n",
    "\n",
    "The following table lists the upcasting conventions in Pandas when NA values are introduced:\n",
    "Typeclass\tConversion When Storing NAs\tNA Sentinel Value\n",
    "* floating - No change - np.nan\n",
    "* object - No change - None or np.nan\n",
    "* integer - Cast to float64 - np.nan\n",
    "* boolean - Cast to object - None or np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. nan  3.  4.]\n",
      "float64 \n",
      "\n",
      "nan \n",
      "\n",
      "nan \n",
      "\n",
      "8.0 4.0\n",
      "\n",
      "0    1.0\n",
      "1    NaN\n",
      "2    2.0\n",
      "3    NaN\n",
      "dtype: float64\n",
      "0    0\n",
      "1    1\n",
      "dtype: int64\n",
      "0    0.0\n",
      "1    NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vals2 = np.array([1, np.nan, 3, 4]) \n",
    "print(vals2)\n",
    "print(vals2.dtype,'\\n')\n",
    "\n",
    "print(np.nan + 1,'\\n')\n",
    "print(vals2.sum(),'\\n')  # Operation of any values with missing data generates missing\n",
    "\n",
    "# Though there are some functions which ignores while doing the operation \n",
    "print(np.nansum(vals2),np.nanmax(vals2))\n",
    "print()\n",
    "\n",
    "# nan and None both together, Pandas automatically type-casts when NA values are present.\n",
    "print(pd.Series([1, np.nan, 2, None]))\n",
    "\n",
    "x = pd.Series(range(2), dtype=int)\n",
    "print(x)\n",
    "x[1,1]=None\n",
    "print(x) # Type change to floating point from integer and None changes to NaN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating on Null Values\n",
    "\n",
    "### Detecting/ Dropping/Filling Null values\n",
    "There are several useful methods for detecting, removing, and replacing null values in Pandas data structures. They are:\n",
    "\n",
    "* isnull(): Generate a boolean mask indicating missing values\n",
    "* notnull(): Opposite of isnull()\n",
    "* dropna(): Return a filtered version of the data\n",
    "* fillna(): Return a copy of the data with missing values filled or imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1      NaN\n",
      "2    hello\n",
      "3     None\n",
      "dtype: object \n",
      "\n",
      "object \n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool \n",
      "\n",
      "0        1\n",
      "2    hello\n",
      "dtype: object \n",
      "\n",
      "0        1\n",
      "2    hello\n",
      "dtype: object \n",
      "\n",
      "     0    1  2\n",
      "1  2.0  3.0  5\n",
      "   2\n",
      "0  2\n",
      "1  5\n",
      "2  6\n",
      "     0    1  2\n",
      "0  1.0  NaN  2\n",
      "1  2.0  3.0  5\n",
      "2  NaN  4.0  6\n",
      "   2\n",
      "0  2\n",
      "1  5\n",
      "2  6\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([1, np.nan, 'hello', None])\n",
    "print(data, '\\n')\n",
    "print(data.dtype, '\\n') # type is object, because we have different types of values\n",
    "\n",
    "# Detecting\n",
    "print(data.isnull(), '\\n')\n",
    "print(data[data.notnull()], '\\n')\n",
    "\n",
    "# Dropping\n",
    "print(data.dropna(), '\\n')\n",
    "\n",
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "print(df.dropna()) # dropping all rows which have missing values in any column\n",
    "print(df.dropna(axis=1)) # dropping all columns which have any missing value\n",
    "\n",
    "print(df.dropna(axis='columns', how='all')) # drops columns if all values are missing\n",
    "print(df.dropna(axis= 1, thresh=3))  # drops columns if atleast 3 values are non-missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1.0\n",
      "b    NaN\n",
      "c    2.0\n",
      "d    NaN\n",
      "e    3.0\n",
      "dtype: float64 \n",
      "\n",
      "a    1.0\n",
      "b    0.0\n",
      "c    2.0\n",
      "d    0.0\n",
      "e    3.0\n",
      "dtype: float64 \n",
      "\n",
      "a    1.0\n",
      "b    1.0\n",
      "c    2.0\n",
      "d    2.0\n",
      "e    3.0\n",
      "dtype: float64\n",
      "     0    1  2\n",
      "0  1.0  NaN  2\n",
      "1  2.0  3.0  5\n",
      "2  NaN  4.0  6\n",
      "     0    1    2\n",
      "0  1.0  2.0  2.0\n",
      "1  2.0  3.0  5.0\n",
      "2  4.0  4.0  6.0\n"
     ]
    }
   ],
   "source": [
    "# Filling Null values\n",
    "data = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\n",
    "print(data,'\\n')\n",
    "\n",
    "print(data.fillna(0),'\\n')\n",
    "\n",
    "# We can specify a forward-fill to propagate the previous value forward:\n",
    "print(data.fillna(method = 'ffill'))\n",
    "\n",
    "print(df)\n",
    "print(df.fillna(method='bfill', axis='columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Indexing\n",
    "\n",
    "When we need to store higher-dimensional (>2-d) data–that is, data indexed by more than one or two keys:\n",
    "\n",
    "* Pandas does provide Panel and Panel4D objects that natively handle three-dimensional and four-dimensional data (see Aside: Panel Data), \n",
    "\n",
    "* But a far more common pattern in practice is to make use of hierarchical indexing (also known as multi-indexing) to incorporate multiple index levels within a single index. In this way, higher-dimensional data can be compactly represented within the familiar one-dimensional Series and two-dimensional DataFrame objects.\n",
    "\n",
    "### Pandas MultiIndex\n",
    "#### The bad way\n",
    "Tuple based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(California, 2000)    33871648\n",
      "(California, 2010)    37253956\n",
      "(New York, 2000)      18976457\n",
      "(New York, 2010)      19378102\n",
      "(Texas, 2000)         20851820\n",
      "(Texas, 2010)         25145561\n",
      "dtype: int64 \n",
      "\n",
      "(California, 2010)    37253956\n",
      "(New York, 2000)      18976457\n",
      "(New York, 2010)      19378102\n",
      "(Texas, 2000)         20851820\n",
      "dtype: int64 \n",
      "\n",
      "(California, 2010)    37253956\n",
      "(New York, 2010)      19378102\n",
      "(Texas, 2010)         25145561\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Provice multiple indexes as itemset (tuple) instead of a single value\n",
    "index = [('California', 2000), ('California', 2010),\n",
    "         ('New York', 2000), ('New York', 2010),\n",
    "         ('Texas', 2000), ('Texas', 2010)]\n",
    "populations = [33871648, 37253956,\n",
    "               18976457, 19378102,\n",
    "               20851820, 25145561]\n",
    "pop = pd.Series(populations, index=index)\n",
    "print(pop,'\\n')\n",
    "print(pop[('California', 2010):('Texas', 2000)],'\\n')\n",
    "\n",
    "# But the convenience ends here. For example, if you need to select all values from 2010, \n",
    "# you'll need to do some messy (and potentially slow) munging to make it happen\n",
    "\n",
    "# To select all the rows with year 2010\n",
    "print(pop[[i for i in pop.index if i[1] == 2010]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Good way\n",
    "\n",
    "Fortunately, Pandas provides a better way. Our tuple-based indexing is essentially a rudimentary multi-index, and the Pandas MultiIndex type gives us the type of operations we wish to have.\n",
    "\n",
    "Each extra level in a multi-index represents an extra dimension of data; taking advantage of this property gives us much more flexibility in the types of data we can represent.\n",
    "\n",
    "We can create a multi-index from the tuples as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex(levels=[['California', 'New York', 'Texas'], [2000, 2010]],\n",
      "           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]]) \n",
      "\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "dtype: int64\n",
      "California    37253956\n",
      "New York      19378102\n",
      "Texas         25145561\n",
      "dtype: int64\n",
      "                2000      2010\n",
      "California  33871648  37253956\n",
      "New York    18976457  19378102\n",
      "Texas       20851820  25145561\n"
     ]
    }
   ],
   "source": [
    "# We can covernt tuple based indexing to multilevel indexing.\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(index)\n",
    "print(index,'\\n')\n",
    "\n",
    "# reindex the data \n",
    "pop = pop.reindex(index)\n",
    "\n",
    "print(pop)\n",
    "\n",
    "# Now to access all data for which the second index is 2010\n",
    "print(pop[:,2010])\n",
    "\n",
    "# Change the second index to columns\n",
    "print(pop.unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods of creating Multi-level Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        data1     data2\n",
      "a 1  0.734921  0.662366\n",
      "  2  0.955336  0.567087\n",
      "b 1  0.004076  0.317176\n",
      "  2  0.758923  0.759330 \n",
      "\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. List of lists as index Or Numpy Matrix\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(4, 2),\n",
    "                  index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                  columns=['data1', 'data2'])\n",
    "print(df,'\\n')\n",
    "\n",
    "#2. Dictionary as dataset and tuples as keys (indices)\n",
    "data = {('California', 2000): 33871648,\n",
    "        ('California', 2010): 37253956,\n",
    "        ('Texas', 2000): 20851820,\n",
    "        ('Texas', 2010): 25145561,\n",
    "        ('New York', 2000): 18976457,\n",
    "        ('New York', 2010): 19378102}\n",
    "print(pd.Series(data),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit Multi-Index Creation\n",
    "You can use the class method constructors available in the pd.MultiIndex. \n",
    "\n",
    "Any of these objects can be passed as the index argument when creating a Series or Dataframe, or be passed to the reindex method of an existing Series or DataFrame.\n",
    "\n",
    "For example, as we did before, you can construct the MultiIndex from a simple list of arrays giving the index values within each level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex(levels=[['a', 'b'], [1, 2]],\n",
      "           labels=[[0, 0, 1, 1], [0, 1, 0, 1]]) \n",
      "\n",
      "MultiIndex(levels=[['a', 'b'], [1, 2]],\n",
      "           labels=[[0, 0, 1, 1], [0, 1, 0, 1]]) \n",
      "\n",
      "MultiIndex(levels=[['a', 'b'], [1, 2]],\n",
      "           labels=[[0, 0, 1, 1], [0, 1, 0, 1]]) \n",
      "\n",
      "MultiIndex(levels=[['a', 'b'], [1, 2]],\n",
      "           labels=[[0, 0, 1, 1], [0, 1, 0, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By Passing Array of Arrays\n",
    "print(pd.MultiIndex.from_arrays([['a', 'a', 'b', 'b'], [1, 2, 1, 2]]), '\\n')\n",
    "\n",
    "# But Passing Tupels\n",
    "print(pd.MultiIndex.from_tuples([('a', 1), ('a', 2), ('b', 1), ('b', 2)]), '\\n')\n",
    "\n",
    "# Just pass the distinct values of different level indexes as array of array, and it will create all the combinations\n",
    "print(pd.MultiIndex.from_product([['a', 'b'], [1, 2]]), '\\n')\n",
    "\n",
    "# Pass its encoding itself as levels and lables arguments.\n",
    "print(pd.MultiIndex(levels=[['a', 'b'], [1, 2]],\n",
    "              labels=[[0, 0, 1, 1], [0, 1, 0, 1]]),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiIndex level names\n",
    "\n",
    "Sometimes it is convenient to name the levels of the MultiIndex. \n",
    "* pass the names argument to any of the above MultiIndex constructors,\n",
    "* or by setting the names attribute of the index after the fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state       year\n",
       "California  2000    33871648\n",
       "            2010    37253956\n",
       "New York    2000    18976457\n",
       "            2010    19378102\n",
       "Texas       2000    20851820\n",
       "            2010    25145561\n",
       "dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.index.names = ['state', 'year']\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Index for Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2010</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2011</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Term1</th>\n",
       "      <th>Term2</th>\n",
       "      <th>Term1</th>\n",
       "      <th>Term2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch</th>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">A</th>\n",
       "      <th>Bio</th>\n",
       "      <td>67.2</td>\n",
       "      <td>58.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maths</th>\n",
       "      <td>68.4</td>\n",
       "      <td>50.4</td>\n",
       "      <td>37.2</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">B</th>\n",
       "      <th>Bio</th>\n",
       "      <td>51.6</td>\n",
       "      <td>55.2</td>\n",
       "      <td>51.6</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maths</th>\n",
       "      <td>37.2</td>\n",
       "      <td>55.2</td>\n",
       "      <td>70.8</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Year           2010        2011      \n",
       "Term          Term1 Term2 Term1 Term2\n",
       "Batch Subject                        \n",
       "A     Bio      67.2  58.8  64.8  64.8\n",
       "      Maths    68.4  50.4  37.2  72.0\n",
       "B     Bio      51.6  55.2  51.6  43.2\n",
       "      Maths    37.2  55.2  70.8  48.0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.MultiIndex.from_product([['A','B'],['Bio','Maths']], names = ['Batch','Subject'])\n",
    "columns = pd.MultiIndex.from_product([[2010,2011],['Term1','Term2']], names = ['Year','Term'])\n",
    "\n",
    "\n",
    "data = pd.DataFrame((np.round(np.random.randn(4,4),1)+5)*12, index=index, columns = columns)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection for Multilevel Index Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term           Term1  Term2\n",
      "Batch Subject              \n",
      "A     Bio       67.2   58.8\n",
      "      Maths     68.4   50.4\n",
      "B     Bio       51.6   55.2\n",
      "      Maths     37.2   55.2 \n",
      "\n",
      "\n",
      "Year           2010      \n",
      "Term          Term1 Term2\n",
      "Batch Subject            \n",
      "A     Bio      67.2  58.8\n",
      "      Maths    68.4  50.4 \n",
      "\n",
      "('A', slice(None, None, None)) \n",
      "\n",
      "Year           2010  2011\n",
      "Term          Term1 Term1\n",
      "Batch Subject            \n",
      "A     Bio      67.2  64.8\n",
      "      Maths    68.4  37.2 \n",
      "\n",
      "Year           2010  2011\n",
      "Term          Term1 Term1\n",
      "Batch Subject            \n",
      "A     Bio      67.2  64.8\n",
      "      Maths    68.4  37.2\n",
      "B     Bio      51.6  51.6\n",
      "      Maths    37.2  70.8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select all columns for first index 2010\n",
    "print(data[2010],'\\n')\n",
    "\n",
    "# Select the column for 2010, Term1\n",
    "data[2010, 'Term1']   # Provide the indexes seprated by comma in the order\n",
    "print()\n",
    "\n",
    "#data[:, 'Term1']   # Partial index on second level is not possible\n",
    "\n",
    "# using iloc\n",
    "print(data.iloc[:2, :2],'\\n')\n",
    "\n",
    "# Using loc and index slice\n",
    "# Select all columns for second index Term1\n",
    "idx = pd.IndexSlice\n",
    "print(idx['A',:],'\\n')\n",
    "print(data.loc[idx['A',:],\n",
    "               idx[:,'Term1']],'\\n')\n",
    "\n",
    "\n",
    "print(data.loc[:,\n",
    "               idx[:,'Term1']],'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange Multi-Indices\n",
    "#### Sorted and Unsorted Indices\n",
    "\n",
    "Many of the MultiIndex slicing operations will fail if the index is not sorted. Let's take a look at this here.\n",
    "\n",
    "We'll start by creating some simple multiply indexed data where the indices are not lexographically sorted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char  int\n",
      "a     1      0.674836\n",
      "      2      0.199036\n",
      "c     1      0.259521\n",
      "      2      0.595678\n",
      "b     1      0.751021\n",
      "      2      0.658135\n",
      "dtype: float64 \n",
      "\n",
      "<class 'pandas.errors.UnsortedIndexError'>\n",
      "'Key length (1) was greater than MultiIndex lexsort depth (0)'\n",
      "char  int\n",
      "a     1      0.674836\n",
      "      2      0.199036\n",
      "b     1      0.751021\n",
      "      2      0.658135\n",
      "c     1      0.259521\n",
      "      2      0.595678\n",
      "dtype: float64\n",
      "char  int\n",
      "a     1      0.674836\n",
      "      2      0.199036\n",
      "b     1      0.751021\n",
      "      2      0.658135\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index = pd.MultiIndex.from_product([['a', 'c', 'b'], [1, 2]])\n",
    "data1 = pd.Series(np.random.rand(6), index=index)\n",
    "data1.index.names = ['char', 'int']\n",
    "print(data1,'\\n')\n",
    "\n",
    "# Slicing fails becuase the indexes are not sorted\n",
    "try:\n",
    "    data1['a':'b']\n",
    "except KeyError as e:\n",
    "    print(type(e))\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "data1.sort_index(inplace=True)\n",
    "\n",
    "print(data1)\n",
    "print(data1['a':'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year           2010        2011      \n",
      "Term          Term1 Term2 Term1 Term2\n",
      "Batch Subject                        \n",
      "A     Bio      67.2  58.8  64.8  64.8\n",
      "      Maths    68.4  50.4  37.2  72.0\n",
      "B     Bio      51.6  55.2  51.6  43.2\n",
      "      Maths    37.2  55.2  70.8  48.0 \n",
      "\n",
      "Year     2010                    2011                  \n",
      "Term    Term1       Term2       Term1       Term2      \n",
      "Subject   Bio Maths   Bio Maths   Bio Maths   Bio Maths\n",
      "Batch                                                  \n",
      "A        67.2  68.4  58.8  50.4  64.8  37.2  64.8  72.0\n",
      "B        51.6  37.2  55.2  55.2  51.6  70.8  43.2  48.0 \n",
      "\n",
      "Year     2010                    2011                  \n",
      "Term    Term1       Term2       Term1       Term2      \n",
      "Batch       A     B     A     B     A     B     A     B\n",
      "Subject                                                \n",
      "Bio      67.2  51.6  58.8  55.2  64.8  51.6  64.8  43.2\n",
      "Maths    68.4  37.2  50.4  55.2  37.2  70.8  72.0  48.0 \n",
      "\n",
      "Year                 2010  2011\n",
      "Batch Subject Term             \n",
      "A     Bio     Term1  67.2  64.8\n",
      "              Term2  58.8  64.8\n",
      "      Maths   Term1  68.4  37.2\n",
      "              Term2  50.4  72.0\n",
      "B     Bio     Term1  51.6  51.6\n",
      "              Term2  55.2  43.2\n",
      "      Maths   Term1  37.2  70.8\n",
      "              Term2  55.2  48.0 \n",
      "\n",
      "Year  Term   Subject  Batch\n",
      "2010  Term1  Bio      A        67.2\n",
      "                      B        51.6\n",
      "             Maths    A        68.4\n",
      "                      B        37.2\n",
      "      Term2  Bio      A        58.8\n",
      "                      B        55.2\n",
      "             Maths    A        50.4\n",
      "                      B        55.2\n",
      "2011  Term1  Bio      A        64.8\n",
      "                      B        51.6\n",
      "             Maths    A        37.2\n",
      "                      B        70.8\n",
      "      Term2  Bio      A        64.8\n",
      "                      B        43.2\n",
      "             Maths    A        72.0\n",
      "                      B        48.0\n",
      "dtype: float64 \n",
      "\n",
      "Batch  Subject  Term   Year\n",
      "A      Bio      Term1  2010    67.2\n",
      "                       2011    64.8\n",
      "                Term2  2010    58.8\n",
      "                       2011    64.8\n",
      "       Maths    Term1  2010    68.4\n",
      "                       2011    37.2\n",
      "                Term2  2010    50.4\n",
      "                       2011    72.0\n",
      "B      Bio      Term1  2010    51.6\n",
      "                       2011    51.6\n",
      "                Term2  2010    55.2\n",
      "                       2011    43.2\n",
      "       Maths    Term1  2010    37.2\n",
      "                       2011    70.8\n",
      "                Term2  2010    55.2\n",
      "                       2011    48.0\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Stacking and Unstacking Indices\n",
    "print(data,'\\n')\n",
    "\n",
    "# Unstack mean dcast the data, means widened the data, means convert the indices to columns\n",
    "print(data.unstack(),'\\n')        # by default it starts unstack from the lower indices\n",
    "print(data.unstack(level=0),'\\n') # we can also provide a level\n",
    "\n",
    "# Stack means melt the data, convert the columns to indices\n",
    "print(data.stack(),'\\n')\n",
    "\n",
    "print(data.unstack().unstack(),'\\n') # We have unstacked the data, since it should become a single row which is a\n",
    "                                     # series, thats why we see it as the column series\n",
    "                       \n",
    "print(data.stack().stack(),'\\n') # We have unstacked the data, since it should become a single row which is a\n",
    "                                     # series, thats why we see it as the column series\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index setting and resetting\n",
    "\n",
    "* **reset_index**\n",
    "Another way to rearrange hierarchical data is to turn the index labels into columns; this can be accomplished with the reset_index method. \n",
    "\n",
    "* **set_index**\n",
    "Often when working with data in the real world, the raw input data looks like this and it's useful to build a MultiIndex from the column values. This can be done with the set_index method of the DataFrame, which returns a multiply indexed DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state       year\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "dtype: int64\n",
      "        state  year  population\n",
      "0  California  2000    33871648\n",
      "1  California  2010    37253956\n",
      "2    New York  2000    18976457\n",
      "3    New York  2010    19378102\n",
      "4       Texas  2000    20851820\n",
      "5       Texas  2010    25145561\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">California</th>\n",
       "      <th>2000</th>\n",
       "      <td>33871648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>37253956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">New York</th>\n",
       "      <th>2000</th>\n",
       "      <td>18976457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>19378102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Texas</th>\n",
       "      <th>2000</th>\n",
       "      <td>20851820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>25145561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 population\n",
       "state      year            \n",
       "California 2000    33871648\n",
       "           2010    37253956\n",
       "New York   2000    18976457\n",
       "           2010    19378102\n",
       "Texas      2000    20851820\n",
       "           2010    25145561"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pop)\n",
    "\n",
    "pop_flat = pop.reset_index(name='population') # converted the state and year indices to columns\n",
    "print(pop_flat)\n",
    "\n",
    "pop_flat.set_index(['state','year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation on muti-indices\n",
    "\n",
    "* axis=1 or2\n",
    "* level = index or column names\n",
    "\n",
    "does the whole job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year           2010        2011      \n",
      "Term          Term1 Term2 Term1 Term2\n",
      "Batch Subject                        \n",
      "A     Bio      67.2  58.8  64.8  64.8\n",
      "      Maths    68.4  50.4  37.2  72.0\n",
      "B     Bio      51.6  55.2  51.6  43.2\n",
      "      Maths    37.2  55.2  70.8  48.0 \n",
      "\n",
      "Year  Term \n",
      "2010  Term1    56.1\n",
      "      Term2    54.9\n",
      "2011  Term1    56.1\n",
      "      Term2    57.0\n",
      "dtype: float64 \n",
      "\n",
      "Batch  Subject\n",
      "A      Bio        63.9\n",
      "       Maths      57.0\n",
      "B      Bio        50.4\n",
      "       Maths      52.8\n",
      "dtype: float64 \n",
      "\n",
      "Term           Term1  Term2\n",
      "Batch Subject              \n",
      "A     Bio       66.0   61.8\n",
      "      Maths     52.8   61.2\n",
      "B     Bio       51.6   49.2\n",
      "      Maths     54.0   51.6 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data,'\\n')\n",
    "\n",
    "print(data.mean(),'\\n') # By defalult for columns across rows\n",
    "\n",
    "print(data.mean(axis='columns'),'\\n') # for rows and across columns\n",
    "\n",
    "print(data.mean(axis ='columns',level='Term'),'\\n') # for rows and across columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining datasets : Concat and Append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(cols, ind):\n",
    "    dicti = {c: [ str(c) + str(i) for i in ind]\n",
    "            for c in cols}\n",
    "    df = pd.DataFrame(dicti, index=ind)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a0</td>\n",
       "      <td>b0</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2</td>\n",
       "      <td>b2</td>\n",
       "      <td>c2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c\n",
       "0  a0  b0  c0\n",
       "1  a1  b1  c1\n",
       "2  a2  b2  c2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_df('abc', range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 1 2 3]\n",
      "\n",
      "1    A\n",
      "2    B\n",
      "3    C\n",
      "4    D\n",
      "5    E\n",
      "6    F\n",
      "dtype: object\n",
      "    A   B\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "1  A1  B1\n",
      "2  A2  B2 \n",
      "\n",
      "    A   B   A   B\n",
      "1  A1  B1  A1  B1\n",
      "2  A2  B2  A2  B2 \n",
      "\n",
      "    A   B\n",
      "0  A1  B1\n",
      "1  A2  B2\n",
      "2  A1  B1\n",
      "3  A2  B2 \n",
      "\n",
      "    0   1   2   3\n",
      "1  A1  B1  A1  B1\n",
      "2  A2  B2  A2  B2 \n",
      "\n",
      "        A   B\n",
      "df1 1  A1  B1\n",
      "    2  A2  B2\n",
      "df2 1  A1  B1\n",
      "    2  A2  B2 \n",
      "\n",
      "  df1     df2    \n",
      "    A   B   A   B\n",
      "1  A1  B1  A1  B1\n",
      "2  A2  B2  A2  B2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recall numpy concatenate function\n",
    "x = np.array([1,2,3])\n",
    "print(np.concatenate([x,x]))\n",
    "#print(np.concatenate([x,x], axis=1)) Doesnot work\n",
    "print('')\n",
    "# Similar to np.concatenate, pandas has concat\n",
    "\n",
    "# Series\n",
    "ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n",
    "ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])\n",
    "print(pd.concat([ser1, ser2]))\n",
    "\n",
    "# Dataframe\n",
    "df1 = make_df('AB', [1, 2])\n",
    "print(pd.concat([df1, df1]),'\\n')           # By default concatenation takes place rows-wise.\n",
    "print(pd.concat([df1, df1],axis=1),'\\n')    # Always can provide axis=1 for column-wise concatenation\n",
    "\n",
    "# As you have seen above, indices in the result dataframe are taken from the original DFs\n",
    "# so there can be overlap or repeting indices.\n",
    "# to handle the repeting indices\n",
    "\n",
    "## raise an exception, if repeting indices or columns\n",
    "# print(pd.concat([df1, df1], verify_integrity = True),'\\n')    \n",
    "# print(pd.concat([df1, df1], axis = 1, verify_integrity = True),'\\n')   \n",
    "\n",
    "## Ignore the indices from the original DFs\n",
    "print(pd.concat([df1, df1], ignore_index = True),'\\n')           # indices are reset\n",
    "print(pd.concat([df1, df1], axis = 1, ignore_index = True),'\\n') # columns are reset to simple number indexing\n",
    "\n",
    "## Add second level key over repeting indexes\n",
    "print(pd.concat([df1, df1], keys = ['df1','df2']),'\\n')           # indices are reset\n",
    "print(pd.concat([df1, df1], axis = 1, keys = ['df1','df2']),'\\n') # columns are reset to simple number indexing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation with Joins\n",
    "Above we just looked at, we were mainly concatenating DataFrames with same column names. \n",
    "Consider the concatenation of the following two DataFrames, which have some (but not all!) columns in common.\n",
    "\n",
    "By default, the entries for which no data is available are filled with NA values. Parameters join and join_axes has multiple values which lets us select columns based on NULL values\n",
    "\n",
    "By default, the join is a union of the input columns (join='outer'), but we can change this to an intersection of the columns using join='inner':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B   C    D\n",
      "1   A1  B1  C1  NaN\n",
      "2   A2  B2  C2  NaN\n",
      "3  NaN  B3  C3   D3\n",
      "4  NaN  B4  C4   D4\n",
      "    B   C\n",
      "1  B1  C1\n",
      "2  B2  C2\n",
      "3  B3  C3\n",
      "4  B4  C4\n",
      "    B   C    D\n",
      "1  B1  C1  NaN\n",
      "2  B2  C2  NaN\n",
      "3  B3  C3   D3\n",
      "4  B4  C4   D4\n",
      "append:\n",
      "     A   B   C    D\n",
      "1   A1  B1  C1  NaN\n",
      "2   A2  B2  C2  NaN\n",
      "3  NaN  B3  C3   D3\n",
      "4  NaN  B4  C4   D4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n",
      "/home/vivek/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "df5 = make_df('ABC', [1, 2])\n",
    "df6 = make_df('BCD', [3, 4])\n",
    "\n",
    "# When to select all the columns of input DFs\n",
    "print(pd.concat([df5, df6])) # Result DF's columns are union of input DF's columns\n",
    "\n",
    "# When to select only shared columns of input DFs\n",
    "print(pd.concat([df5, df6], join='inner'))  # Selects only those columns which are shared by the input DFs\n",
    "\n",
    "# When to select one dataframes all column and shared columns of another DFs, more like left and right join.\n",
    "print(pd.concat([df5, df6], join_axes = [df6.columns]))  # Selects only those columns which are shared by the input DFs\n",
    "\n",
    "# The append method, does the same job as concat but fewer parameters available\n",
    "# But its better to use concat instead of append for runtime efficiency\n",
    "print('append:')\n",
    "print(df5.append(df6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Datasets: Merge and Join\n",
    "\n",
    "Keep in mind that the merge in general discards the index, except in the special case of merges by index (see the left_index and right_index keywords, discussed momentarily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee        group\n",
      "0      Bob   Accounting\n",
      "1     Jake  Engineering\n",
      "2     Lisa  Engineering\n",
      "3      Sue           HR \n",
      "\n",
      "  employee  hire_date\n",
      "0     Lisa       2004\n",
      "1      Bob       2008\n",
      "2     Jake       2012\n",
      "3      Sue       2014 \n",
      "\n",
      "  employee        group  hire_date\n",
      "0      Bob   Accounting       2008\n",
      "1     Jake  Engineering       2012\n",
      "2     Lisa  Engineering       2004\n",
      "3      Sue           HR       2014 \n",
      "\n",
      "  employee        group        skills\n",
      "0      Bob   Accounting          math\n",
      "1      Bob   Accounting  spreadsheets\n",
      "2     Jake  Engineering        coding\n",
      "3     Jake  Engineering         linux\n",
      "4     Lisa  Engineering        coding\n",
      "5     Lisa  Engineering         linux\n",
      "6      Sue           HR  spreadsheets\n",
      "7      Sue           HR  organization \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "df3 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n",
    "                              'Engineering', 'Engineering', 'HR', 'HR'],\n",
    "                    'skills': ['math', 'spreadsheets', 'coding', 'linux',\n",
    "                               'spreadsheets', 'organization']})\n",
    "df4 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'salary': [70000, 80000, 120000, 90000]})\n",
    "print(df1,'\\n')\n",
    "print(df2,'\\n')\n",
    "#print(df3,'\\n')\n",
    "\n",
    "print(pd.merge(df1,df2),'\\n') # Merges on common columns for input DFs\n",
    "print(pd.merge(df1,df3),'\\n') # Merges on common columns for input DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specification of the merge key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee        group  hire_date\n",
      "0      Bob   Accounting       2008\n",
      "1     Jake  Engineering       2012\n",
      "2     Lisa  Engineering       2004\n",
      "3      Sue           HR       2014 \n",
      "\n",
      "  employee        group  name  salary\n",
      "0      Bob   Accounting   Bob   70000\n",
      "1     Jake  Engineering  Jake   80000\n",
      "2     Lisa  Engineering  Lisa  120000\n",
      "3      Sue           HR   Sue   90000 \n",
      "\n",
      "  employee  salary\n",
      "0      Bob   70000\n",
      "1     Jake   80000\n",
      "2     Lisa  120000\n",
      "3      Sue   90000 \n",
      "\n",
      "                group\n",
      "employee             \n",
      "Bob        Accounting\n",
      "Jake      Engineering\n",
      "Lisa      Engineering\n",
      "Sue                HR \n",
      "\n",
      "                group  hire_date\n",
      "employee                        \n",
      "Bob        Accounting       2008\n",
      "Jake      Engineering       2012\n",
      "Lisa      Engineering       2004\n",
      "Sue                HR       2014 \n",
      "\n",
      "Join, defaults on indexes\n",
      "                group  hire_date\n",
      "employee                        \n",
      "Bob        Accounting       2008\n",
      "Jake      Engineering       2012\n",
      "Lisa      Engineering       2004\n",
      "Sue                HR       2014 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------- 'on' keyword ---------------\n",
    "## Specify the column to merge on, instead of default all shared columns\n",
    "print(pd.merge(df1,df2, on='employee'),'\\n') \n",
    "\n",
    "#--------------- 'left_on' and 'right_on' keyword ---------------\n",
    "## Specify the column to merge but that columns has differnt names in the input DFs\n",
    "print(pd.merge(df1,df4, left_on='employee', right_on='name'),'\\n') # Both employee and name columns will retain\n",
    "\n",
    "#--------------- drop the columnd using df.drop(axis=1) method ---------------\n",
    "## to remove the redundant or unwanted columns\n",
    "print(pd.merge(df1,df4, left_on='employee', right_on='name').drop(['name','group'],axis=1), '\\n') \n",
    "\n",
    "df1a = df1.set_index('employee') # move employe column to indices\n",
    "df2a = df2.set_index('employee')\n",
    "print(df1a,'\\n')\n",
    "\n",
    "#--------------- 'left_index' and 'right_index' keywords---------------------------------\n",
    "## merge on indexes rather on columns\n",
    "print(pd.merge(df1a,df2a, left_index=True, right_index=True), '\\n') \n",
    "\n",
    "# we can merge two dataframe on indexes without explicitely mentioning indexes parameters as above\n",
    "print('Join, defaults on indexes')\n",
    "print(df1a.join(df2a), '\\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee        group  hire_date\n",
      "0      Bob   Accounting       2008\n",
      "1     Lisa  Engineering       2004 \n",
      "\n",
      "  employee        group  hire_date\n",
      "0      Bob   Accounting     2008.0\n",
      "1     Lisa  Engineering     2004.0\n",
      "2      Sue           HR        NaN\n",
      "3     Jake          NaN     2012.0 \n",
      "\n",
      "  employee        group  hire_date\n",
      "0      Bob   Accounting     2008.0\n",
      "1     Lisa  Engineering     2004.0\n",
      "2      Sue           HR        NaN \n",
      "\n",
      "  employee        group  hire_date\n",
      "0      Bob   Accounting       2008\n",
      "1     Lisa  Engineering       2004\n",
      "2     Jake          NaN       2012 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------- 'on' keyword ---------------\n",
    "# Dropping some keys from both the data set to explain inner and outer joins\n",
    "df1b = df1.drop(1,axis=0)\n",
    "df2b = df2.drop(3,axis=0)\n",
    "\n",
    "## Get the inner join, give only rows for commone keys\n",
    "print(pd.merge(df1b,df2b, on='employee'),'\\n') # default merge is inner\n",
    "\n",
    "## Get the outer join,\n",
    "print(pd.merge(df1b,df2b, on='employee', how='outer'),'\\n') \n",
    "\n",
    "## Get the outer join,\n",
    "print(pd.merge(df1b,df2b, on='employee', how='left'),'\\n') \n",
    "\n",
    "## Get the outer join,\n",
    "print(pd.merge(df1b,df2b, on='employee', how='right'),'\\n') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Common column names in the dataframes\n",
    "\n",
    "if the column names are common in dataframes to join, the merge function automatically appends a suffix _x or _y to make the output columns unique. If these defaults are inappropriate, it is possible to specify a custom suffix using the suffixes keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee      group_x      group_y\n",
      "0      Bob   Accounting   Accounting\n",
      "1     Lisa  Engineering  Engineering\n",
      "2      Sue           HR           HR \n",
      "\n",
      "  employee   group_left  group_right\n",
      "0      Bob   Accounting   Accounting\n",
      "1     Lisa  Engineering  Engineering\n",
      "2      Sue           HR           HR \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## defaul suffixes for common column names\n",
    "print(pd.merge(df1b,df1b, on='employee'),'\\n') # default merge is inner\n",
    "\n",
    "## Give the required suffixes using parameter suffixes\n",
    "print(pd.merge(df1b,df1b, on='employee', suffixes=['_left','_right']),'\\n') # default merge is inner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------- Aggregation And Grouping-------------------------------------------------------\n",
    "\n",
    "\n",
    "The following table summarizes some other built-in Pandas aggregations:\n",
    "\n",
    "Aggregation\tDescription\n",
    "* count(),     \tTotal number of items\n",
    "* first(), last()\tFirst and last item\n",
    "* mean(), median()\tMean and median\n",
    "* min(), max()\tMinimum and maximum\n",
    "* std(), var()\tStandard deviation and variance\n",
    "* mad()\tMean absolute deviation\n",
    "* prod()\tProduct of all items\n",
    "* sum()\tSum of all items\n",
    "\n",
    "These are all methods of DataFrame and Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>number</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>mass</th>\n",
       "      <th>distance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>269.300</td>\n",
       "      <td>7.10</td>\n",
       "      <td>77.40</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>874.774</td>\n",
       "      <td>2.21</td>\n",
       "      <td>56.95</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>763.000</td>\n",
       "      <td>2.60</td>\n",
       "      <td>19.84</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>326.030</td>\n",
       "      <td>19.40</td>\n",
       "      <td>110.62</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>516.220</td>\n",
       "      <td>10.50</td>\n",
       "      <td>119.47</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            method  number  orbital_period   mass  distance  year\n",
       "0  Radial Velocity       1         269.300   7.10     77.40  2006\n",
       "1  Radial Velocity       1         874.774   2.21     56.95  2008\n",
       "2  Radial Velocity       1         763.000   2.60     19.84  2011\n",
       "3  Radial Velocity       1         326.030  19.40    110.62  2007\n",
       "4  Radial Velocity       1         516.220  10.50    119.47  2009"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import planets data from seaborn\n",
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.shape\n",
    "planets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            number  orbital_period        mass     distance         year\n",
      "count  1035.000000      992.000000  513.000000   808.000000  1035.000000\n",
      "mean      1.785507     2002.917596    2.638161   264.069282  2009.070531\n",
      "std       1.240976    26014.728304    3.818617   733.116493     3.972567\n",
      "min       1.000000        0.090706    0.003600     1.350000  1989.000000\n",
      "25%       1.000000        5.442540    0.229000    32.560000  2007.000000\n",
      "50%       1.000000       39.979500    1.260000    55.250000  2010.000000\n",
      "75%       2.000000      526.005000    3.040000   178.500000  2012.000000\n",
      "max       7.000000   730000.000000   25.000000  8500.000000  2014.000000 \n",
      "\n",
      "          number  orbital_period        mass    distance         year\n",
      "count  498.00000      498.000000  498.000000  498.000000   498.000000\n",
      "mean     1.73494      835.778671    2.509320   52.068213  2007.377510\n",
      "std      1.17572     1469.128259    3.636274   46.596041     4.167284\n",
      "min      1.00000        1.328300    0.003600    1.350000  1989.000000\n",
      "25%      1.00000       38.272250    0.212500   24.497500  2005.000000\n",
      "50%      1.00000      357.000000    1.245000   39.940000  2009.000000\n",
      "75%      2.00000      999.600000    2.867500   59.332500  2011.000000\n",
      "max      6.00000    17337.500000   25.000000  354.000000  2014.000000\n"
     ]
    }
   ],
   "source": [
    "#there is a convenience method describe() that computes several common aggregates for each column and returns \n",
    "# the result.\n",
    "\n",
    "# It drops the missings for an column individually.\n",
    "print(planets.describe(),'\\n')\n",
    "\n",
    "# dropna() drops all the rows which have any value missing\n",
    "print(planets.dropna().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy: Split, Apply, Combine\n",
    "Simple aggregations can give you a flavor of your dataset, but often we would prefer to aggregate conditionally on some label or index: this is implemented in the so-called groupby operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  data\n",
      "0   A     0\n",
      "1   B     1\n",
      "2   C     2\n",
      "3   A     3\n",
      "4   B     4\n",
      "5   C     5 \n",
      "\n",
      "<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x7fd729a53e90> \n",
      "\n",
      "     data\n",
      "key      \n",
      "A       3\n",
      "B       5\n",
      "C       7 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': range(6)}, columns=['key', 'data'])\n",
    "print(df,'\\n')\n",
    "\n",
    "# Notice that what is returned is not a set of DataFrames, but a DataFrameGroupBy object. This object is where the \n",
    "# magic is: you can think of it as a special view of the DataFrame, which is poised to dig into the groups but \n",
    "# does no actual computation until the aggregation is applied. This \"lazy evaluation\" approach means that \n",
    "# common aggregates can be implemented very efficiently in a way that is almost transparent to the user.\n",
    "print(df.groupby('key'),'\\n')\n",
    "\n",
    "# To produce a result, we can apply an aggregate to this DataFrameGroupBy object\n",
    "print(df.groupby('key').sum(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GroupBy Object\n",
    "\n",
    "The GroupBy object is a very flexible abstraction. In many ways, you can simply treat it as if it's a collection of DataFrames, and it does the difficult things under the hood. Let's see some examples using the Planets data.\n",
    "\n",
    "Perhaps the most important operations made available by a GroupBy are aggregate, filter, transform, and apply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Radial Velocity' 'Imaging' 'Eclipse Timing Variations' 'Transit'\n",
      " 'Astrometry' 'Transit Timing Variations' 'Orbital Brightness Modulation'\n",
      " 'Microlensing' 'Pulsar Timing' 'Pulsation Timing Variations'] \n",
      "\n",
      "<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x7fd729a53d50> \n",
      "\n",
      "<pandas.core.groupby.groupby.SeriesGroupBy object at 0x7fd72acb3890> \n",
      "\n",
      "\n",
      "Summing the orbital_period conditioned on method column\n",
      "method\n",
      "Astrometry                       1.262360e+03\n",
      "Eclipse Timing Variations        4.276480e+04\n",
      "Imaging                          1.418973e+06\n",
      "Microlensing                     2.207500e+04\n",
      "Orbital Brightness Modulation    2.127920e+00\n",
      "Pulsar Timing                    3.671511e+04\n",
      "Pulsation Timing Variations      1.170000e+03\n",
      "Radial Velocity                  4.553151e+05\n",
      "Transit                          8.377523e+03\n",
      "Transit Timing Variations        2.393505e+02\n",
      "Name: orbital_period, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(planets.method.unique(),'\\n')\n",
    "\n",
    "# create a DataFrameGroupBy Object for \"planets\" data conditioned on \"method\" column\n",
    "print(planets.groupby('method'),'\\n')\n",
    "\n",
    "# Let's select a particular Series group from the original DataFrame group by reference to its column name. \n",
    "# As with the GroupBy object, no computation is done until we call some aggregate on the object.\n",
    "print( planets.groupby('method')['orbital_period'],'\\n\\n')\n",
    "\n",
    "# Now perform sum on the selected group above\n",
    "print('Summing the orbital_period conditioned on method column')\n",
    "print( planets.groupby('method')['orbital_period'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration over groups\n",
    "The GroupBy object supports direct iteration over the groups, returning each group as a Series or DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrometry                               shape(2, 6)\n",
      "Eclipse Timing Variations                shape(9, 6)\n",
      "Imaging                                  shape(38, 6)\n",
      "Microlensing                             shape(23, 6)\n",
      "Orbital Brightness Modulation            shape(3, 6)\n",
      "Pulsar Timing                            shape(5, 6)\n",
      "Pulsation Timing Variations              shape(1, 6)\n",
      "Radial Velocity                          shape(553, 6)\n",
      "Transit                                  shape(397, 6)\n",
      "Transit Timing Variations                shape(4, 6)\n"
     ]
    }
   ],
   "source": [
    "for (method,group) in planets.groupby('method'):\n",
    "    print(\"{0:40s} shape{1}\".format(method,group.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Astrometry</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.875000</td>\n",
       "      <td>4.094148</td>\n",
       "      <td>14.98</td>\n",
       "      <td>16.4275</td>\n",
       "      <td>17.875</td>\n",
       "      <td>19.3225</td>\n",
       "      <td>20.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eclipse Timing Variations</th>\n",
       "      <td>4.0</td>\n",
       "      <td>315.360000</td>\n",
       "      <td>213.203907</td>\n",
       "      <td>130.72</td>\n",
       "      <td>130.7200</td>\n",
       "      <td>315.360</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imaging</th>\n",
       "      <td>32.0</td>\n",
       "      <td>67.715937</td>\n",
       "      <td>53.736817</td>\n",
       "      <td>7.69</td>\n",
       "      <td>22.1450</td>\n",
       "      <td>40.395</td>\n",
       "      <td>132.6975</td>\n",
       "      <td>165.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microlensing</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4144.000000</td>\n",
       "      <td>2076.611556</td>\n",
       "      <td>1760.00</td>\n",
       "      <td>2627.5000</td>\n",
       "      <td>3840.000</td>\n",
       "      <td>4747.5000</td>\n",
       "      <td>7720.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbital Brightness Modulation</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1180.00</td>\n",
       "      <td>1180.0000</td>\n",
       "      <td>1180.000</td>\n",
       "      <td>1180.0000</td>\n",
       "      <td>1180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsar Timing</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1200.0000</td>\n",
       "      <td>1200.000</td>\n",
       "      <td>1200.0000</td>\n",
       "      <td>1200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsation Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radial Velocity</th>\n",
       "      <td>530.0</td>\n",
       "      <td>51.600208</td>\n",
       "      <td>45.559381</td>\n",
       "      <td>1.35</td>\n",
       "      <td>24.4125</td>\n",
       "      <td>40.445</td>\n",
       "      <td>59.2175</td>\n",
       "      <td>354.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit</th>\n",
       "      <td>224.0</td>\n",
       "      <td>599.298080</td>\n",
       "      <td>913.876990</td>\n",
       "      <td>38.00</td>\n",
       "      <td>200.0000</td>\n",
       "      <td>341.000</td>\n",
       "      <td>650.0000</td>\n",
       "      <td>8500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit Timing Variations</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1104.333333</td>\n",
       "      <td>915.819487</td>\n",
       "      <td>339.00</td>\n",
       "      <td>597.0000</td>\n",
       "      <td>855.000</td>\n",
       "      <td>1487.0000</td>\n",
       "      <td>2119.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count         mean          std      min  \\\n",
       "method                                                                    \n",
       "Astrometry                       2.0    17.875000     4.094148    14.98   \n",
       "Eclipse Timing Variations        4.0   315.360000   213.203907   130.72   \n",
       "Imaging                         32.0    67.715937    53.736817     7.69   \n",
       "Microlensing                    10.0  4144.000000  2076.611556  1760.00   \n",
       "Orbital Brightness Modulation    2.0  1180.000000     0.000000  1180.00   \n",
       "Pulsar Timing                    1.0  1200.000000          NaN  1200.00   \n",
       "Pulsation Timing Variations      0.0          NaN          NaN      NaN   \n",
       "Radial Velocity                530.0    51.600208    45.559381     1.35   \n",
       "Transit                        224.0   599.298080   913.876990    38.00   \n",
       "Transit Timing Variations        3.0  1104.333333   915.819487   339.00   \n",
       "\n",
       "                                     25%       50%        75%      max  \n",
       "method                                                                  \n",
       "Astrometry                       16.4275    17.875    19.3225    20.77  \n",
       "Eclipse Timing Variations       130.7200   315.360   500.0000   500.00  \n",
       "Imaging                          22.1450    40.395   132.6975   165.00  \n",
       "Microlensing                   2627.5000  3840.000  4747.5000  7720.00  \n",
       "Orbital Brightness Modulation  1180.0000  1180.000  1180.0000  1180.00  \n",
       "Pulsar Timing                  1200.0000  1200.000  1200.0000  1200.00  \n",
       "Pulsation Timing Variations          NaN       NaN        NaN      NaN  \n",
       "Radial Velocity                  24.4125    40.445    59.2175   354.00  \n",
       "Transit                         200.0000   341.000   650.0000  8500.00  \n",
       "Transit Timing Variations       597.0000   855.000  1487.0000  2119.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dispatch Methods\n",
    "planets.groupby('method')['distance'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby : Aggregation, Filter, Transform, Apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  data1  data2\n",
       "0   A      0      5\n",
       "1   B      1      0\n",
       "2   C      2      3\n",
       "3   A      3      3\n",
       "4   B      4      7\n",
       "5   C      5      9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data1': range(6),\n",
    "                   'data2': rng.randint(0, 10, 6)},\n",
    "                   columns = ['key', 'data1', 'data2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    data1            data2           \n",
      "      min median max   min median max\n",
      "key                                  \n",
      "A       0    1.5   3     3    4.0   5\n",
      "B       1    2.5   4     0    3.5   7\n",
      "C       2    3.5   5     3    6.0   9\n",
      "\n",
      "     data1  data2\n",
      "key              \n",
      "A        3      2\n",
      "B        5      2\n",
      "C        7      2\n"
     ]
    }
   ],
   "source": [
    "# Aggregation\n",
    "\n",
    "## aggregate() method allows for even more flexibility. It can take a string, a function, or a list thereof, \n",
    "## and compute all the aggregates at once.\n",
    "print(df.groupby('key').aggregate(['min',np.median,max]))\n",
    "print()\n",
    "\n",
    "## Another useful pattern is to pass a dictionary mapping of column namse to operations to be applied on that columns\n",
    "print(df.groupby('key').aggregate({'data1': np.sum, 'data2': 'count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{df['data2'].std()>4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  data1  data2\n",
       "1   B      1      0\n",
       "2   C      2      3\n",
       "4   B      4      7\n",
       "5   C      5      9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter\n",
    "## A filtering operation allows you to drop data based on the group properties. \n",
    "## For example, we might want to keep all groups in which the standard deviation is larger than some critical value:\n",
    "\n",
    "# This can be done by passing a function to the filter method, which defined the criteria to filter\n",
    "# Note that, The filter function should return a Boolean value specifying whether the group passes the filtering\n",
    "df.groupby('key').filter(lambda x : x['data2'].std() > 4 )\n",
    "\n",
    "#OR\n",
    "\n",
    "def pass_criteria(x):\n",
    "    return x['data2'].std() > 4\n",
    "\n",
    "df.groupby('key').filter(pass_criteria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>-3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data1  data2\n",
       "0   -1.5    1.0\n",
       "1   -1.5   -3.5\n",
       "2   -1.5   -3.0\n",
       "3    1.5   -1.0\n",
       "4    1.5    3.5\n",
       "5    1.5    3.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation\n",
    "\n",
    "# While aggregation must return a reduced version of the data, transformation can return some transformed version \n",
    "# of the full data to recombine. For such a transformation, the output is the same shape as the input.\n",
    "# A common example is to center the data by subtracting the group-wise mean:\n",
    "\n",
    "#***** It returns all the columns passed to the transform function after applying the required operation******\n",
    "\n",
    "# we have pass a function to transform to do the required operations\n",
    "df.groupby('key').transform( lambda x: x- x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  data1  data2  data3\n",
       "0   A      0      5      5\n",
       "1   B      1      0      1\n",
       "2   C      2      3      5\n",
       "3   A      3      3      6\n",
       "4   B      4      7     11\n",
       "5   C      5      9     14"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply\n",
    "\n",
    "# The apply() method lets you apply an arbitrary function to the group results. The function should take a DataFrame,\n",
    "# and return either a Pandas object (e.g., DataFrame, Series) or a scalar; the combine operation will be tailored to \n",
    "# the type of output returned.\n",
    "\n",
    "# unlike Transformation where it takes a series where operations are applied on that particular series\n",
    "# apply takes the whole group results (dataframegroupby) and we can use multiple columns for a single operations\n",
    "\n",
    "#***** It returns the whole dataframe passed to groupby, instead of only columns ***********\n",
    "\n",
    "# For example, here is an apply() that creates a column with sum of first and second column:\n",
    "def fun(dfg):\n",
    "    dfg['data3'] = dfg['data1'] + dfg['data2'] \n",
    "    return(dfg)\n",
    "df.groupby('key').apply(fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the split key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not A</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data1  data2\n",
       "A          3      8\n",
       "not A     12     19"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By Specifying any columnname\n",
    "df.groupby('key').mean()\n",
    "\n",
    "# By columnt itself\n",
    "df.groupby(df['key']).mean()\n",
    "\n",
    "# By list of column names or columns\n",
    "df.groupby(['key']).mean()\n",
    "\n",
    "# By an external list\n",
    "l = ['a','b','c','a','b','c']\n",
    "df.groupby(l).mean()\n",
    "\n",
    "# By index, or any external series\n",
    "df2 = df.set_index('key')  # set the key column as index for the dataframe\n",
    "df.groupby(df2.index).mean()\n",
    "\n",
    "# By a dictionary : the dictionary maps indices of dataframe to groups\n",
    "mappings = {'A':'vowels','B':'consonants','C':'consonants'}\n",
    "mappings = dict(zip( ['A','B','C'],\n",
    "                     ['vowels','consonants','consonants']\n",
    "                   )\n",
    "               )\n",
    "df2.groupby(mappings).mean()\n",
    "\n",
    "# By any python function which needs to apply on indexes\n",
    "\n",
    "# on textual indices we have use string's lower case method\n",
    "df2.groupby(str.lower).sum()    \n",
    "\n",
    "# for all the indices we recatogrized them into two keys\n",
    "def re_categorize(x):\n",
    "    if x=='A':\n",
    "        return x\n",
    "    else:\n",
    "        return 'not A'\n",
    "    \n",
    "df2.groupby(re_categorize).sum()    \n",
    "\n",
    "# on integer indices we just did a sum of alternate rows \n",
    "df.groupby(lambda x: x%2 == 0).sum()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy : Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>number</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>mass</th>\n",
       "      <th>distance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>269.300</td>\n",
       "      <td>7.10</td>\n",
       "      <td>77.40</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>874.774</td>\n",
       "      <td>2.21</td>\n",
       "      <td>56.95</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>763.000</td>\n",
       "      <td>2.60</td>\n",
       "      <td>19.84</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>326.030</td>\n",
       "      <td>19.40</td>\n",
       "      <td>110.62</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>516.220</td>\n",
       "      <td>10.50</td>\n",
       "      <td>119.47</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            method  number  orbital_period   mass  distance  year\n",
       "0  Radial Velocity       1         269.300   7.10     77.40  2006\n",
       "1  Radial Velocity       1         874.774   2.21     56.95  2008\n",
       "2  Radial Velocity       1         763.000   2.60     19.84  2011\n",
       "3  Radial Velocity       1         326.030  19.40    110.62  2007\n",
       "4  Radial Velocity       1         516.220  10.50    119.47  2009"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>decades</th>\n",
       "      <th>1980s</th>\n",
       "      <th>1990s</th>\n",
       "      <th>2000s</th>\n",
       "      <th>2010s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Astrometry</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eclipse Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imaging</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microlensing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbital Brightness Modulation</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsar Timing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsation Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radial Velocity</th>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "decades                        1980s  1990s  2000s  2010s\n",
       "method                                                   \n",
       "Astrometry                       0.0    0.0    0.0    2.0\n",
       "Eclipse Timing Variations        0.0    0.0    5.0   10.0\n",
       "Imaging                          0.0    0.0   29.0   21.0\n",
       "Microlensing                     0.0    0.0   12.0   15.0\n",
       "Orbital Brightness Modulation    0.0    0.0    0.0    5.0\n",
       "Pulsar Timing                    0.0    9.0    1.0    1.0\n",
       "Pulsation Timing Variations      0.0    0.0    1.0    0.0\n",
       "Radial Velocity                  1.0   52.0  475.0  424.0\n",
       "Transit                          0.0    0.0   64.0  712.0\n",
       "Transit Timing Variations        0.0    0.0    0.0    9.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count discovered planets by method and by decade\n",
    "decades = 10* (planets['year']//10)\n",
    "decades = decades.astype('str') + 's'\n",
    "decades.name = 'decades'\n",
    "planets.groupby([decades,'method'])['number'].sum().unstack('decades').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables\n",
    "\n",
    "We have seen how the GroupBy abstraction lets us explore relationships within a dataset. A pivot table is a similar operation that is commonly seen in spreadsheets and other programs that operate on tabular data. The pivot table takes simple column-wise data as input, and groups the entries into a two-dimensional table that provides a multidimensional summarization of the data.\n",
    "\n",
    "pivot tables as essentially a multidimensional version of GroupBy aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "titanic[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class   First  Second  Third\n",
       "sex                         \n",
       "female   0.97    0.92   0.50\n",
       "male     0.37    0.16   0.14"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot table using groupby\n",
    "#survival_c_gender = titanic.groupby('sex').aggregate({'survived':[np.sum,'count']})\n",
    "#survival_c_gender['survived','%'] = '%' + np.round(100* (survival_c_gender['survived','sum']/survival_c_gender['survived','count'])).astype('str')\n",
    "titanic.groupby('sex')[['survived']].mean().round(2)\n",
    "\n",
    "# lets explore a bit more looking at survival conditioned on sex and class both\n",
    "titanic.groupby(['sex','class'])['survived'].mean().round(2).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class   First  Second  Third\n",
       "sex                         \n",
       "female   0.97    0.92   0.50\n",
       "male     0.37    0.16   0.14"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can create the above table using more readable code using pivot_table method\n",
    "titanic.pivot_table('survived', index='sex', columns='class').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">female</th>\n",
       "      <th>(0, 18]</th>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.511628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(18, 80]</th>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.423729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">male</th>\n",
       "      <th>(0, 18]</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.215686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(18, 80]</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.133663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sum                   mean                    \n",
       "class           First Second Third     First    Second     Third\n",
       "sex    age                                                      \n",
       "female (0, 18]     10     14    22  0.909091  1.000000  0.511628\n",
       "       (18, 80]    72     54    25  0.972973  0.900000  0.423729\n",
       "male   (0, 18]      4      9    11  0.800000  0.600000  0.215686\n",
       "       (18, 80]    36      6    27  0.375000  0.071429  0.133663"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple level table\n",
    "age_bin = pd.cut(titanic['age'],[0,18,80])\n",
    "titanic.pivot_table('survived', index=['sex',age_bin], columns='class', aggfunc=['sum','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class   First  Second  Third   All\n",
       "sex                               \n",
       "female   0.97    0.92   0.50  0.74\n",
       "male     0.37    0.16   0.14  0.19\n",
       "All      0.63    0.47   0.24  0.38"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can sepcify multiple columns and operations on them\n",
    "titanic.pivot_table('survived', index='sex', columns='class',margins=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing string Operation\n",
    "\n",
    "\n",
    "This vectorization of operations simplifies the syntax of operating on arrays of data: we no longer have to worry about the size or shape of the array, but just about what operation we want done. \n",
    "\n",
    "For arrays of strings, NumPy does not provide such simple access, but Pandas includes features to address both this need for vectorized string operations and for correctly handling missing data via the str attribute.\n",
    "\n",
    "Methods similar to Python string methods\n",
    "Nearly all Python's built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas str methods that mirror Python string methods:\n",
    "\n",
    "len()\t  lower()\ttranslate()\tislower()\n",
    "\n",
    "ljust()\t  upper()\tstartswith()\tisupper()\n",
    "\n",
    "rjust()\tfind()\tendswith()\tisnumeric()\n",
    "\n",
    "center()\trfind()\tisalnum()\tisdecimal()\n",
    "\n",
    "zfill()\tindex()\tisalpha()\tsplit()\n",
    "\n",
    "strip()\trindex()\tisdigit()\trsplit()\n",
    "\n",
    "rstrip()\tcapitalize()\tisspace()\tpartition()\n",
    "\n",
    "lstrip()\tswapcase()\tistitle()\trpartition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vivek', 'Singh', 'Solanki88'] \n",
      "\n",
      "0        vivek\n",
      "1        singh\n",
      "2         None\n",
      "3    solanki88\n",
      "dtype: object \n",
      "\n",
      "0        Vivek\n",
      "1        Singh\n",
      "2         None\n",
      "3    Solanki88\n",
      "dtype: object\n",
      "0    5.0\n",
      "1    5.0\n",
      "2    NaN\n",
      "3    9.0\n",
      "dtype: float64\n",
      "0        [v, vek]\n",
      "1        [s, ngh]\n",
      "2            None\n",
      "3    [solank, 88]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "str_array = ['vivek','singh','solanki88']\n",
    "print([s.capitalize() for s in str_array],'\\n')       # Arrays doesnot support string vectorization\n",
    "\n",
    "str_array = ['vivek','singh',None, 'solanki88']\n",
    "#[s.capitalize() for s in str_array]       # Arrays doesnot support missing data handling for strings\n",
    "\n",
    "str_series = pd.Series(str_array)\n",
    "print(str_series,'\\n')\n",
    "print(str_series.str.capitalize())         # Pandas prvoides vectorized string operations as well handling of data\n",
    "\n",
    "print(str_series.str.len())\n",
    "\n",
    "\n",
    "print(str_series.str.split('i'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized string operations : Methods using regular expressions\n",
    "In addition, there are several methods that accept regular expressions to examine the content of each string element, and follow some of the API conventions of Python's built-in re module:\n",
    "\n",
    "Method\tDescription\n",
    "\n",
    "match()\tCall re.match() on each element, returning a boolean.\n",
    "\n",
    "extract()\tCall re.match() on each element, returning matched groups as strings.\n",
    "\n",
    "findall()\tCall re.findall() on each element\n",
    "\n",
    "replace()\tReplace occurrences of pattern with some other string\n",
    "\n",
    "contains()\tCall re.search() on each element, returning a boolean\n",
    "\n",
    "count()\tCount occurrences of pattern\n",
    "\n",
    "split()\tEquivalent to str.split(), but accepts regexps\n",
    "\n",
    "rsplit()\tEquivalent to str.rsplit(), but accepts regexps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        vivek\n",
      "1        singh\n",
      "2         None\n",
      "3    solanki88\n",
      "dtype: object \n",
      "\n",
      "0      vivek\n",
      "1      singh\n",
      "2        NaN\n",
      "3    solanki\n",
      "dtype: object \n",
      "\n",
      "0        [vivek]\n",
      "1        [singh]\n",
      "2           None\n",
      "3    [solanki88]\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str_series,'\\n')\n",
    "print(str_series.str.extract('([A-Za-z]+)', expand=False),'\\n')\n",
    "print(str_series.str.findall('^[^AEIOU].*[^aeiou]$'),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized string operations : Miscellaneous methods\n",
    "Finally, there are some miscellaneous methods that enable other convenient operations:\n",
    "\n",
    "Method\tDescription\n",
    "\n",
    "get()\tIndex each element\n",
    "\n",
    "slice()\tSlice each element\n",
    "\n",
    "slice_replace()\tReplace slice in each element with passed value\n",
    "\n",
    "cat()\tConcatenate strings\n",
    "\n",
    "repeat()\tRepeat values\n",
    "\n",
    "normalize()\tReturn Unicode form of string\n",
    "\n",
    "pad()\tAdd whitespace to left, right, or both sides of strings\n",
    "\n",
    "wrap()\tSplit long strings into lines with length less than a given width\n",
    "\n",
    "join()\tJoin strings in each element of the Series with passed separator\n",
    "\n",
    "get_dummies()\textract dummy variables as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      vi\n",
      "1      si\n",
      "2    None\n",
      "3      so\n",
      "dtype: object \n",
      "\n",
      "0      vi\n",
      "1      si\n",
      "2    None\n",
      "3      so\n",
      "dtype: object \n",
      "\n",
      "0     vek\n",
      "1     ngh\n",
      "2    None\n",
      "3      88\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(str_series.str.slice(0,2),'\\n')\n",
    "print(str_series.str[0:2],'\\n')  # or equivalent for slicing\n",
    "\n",
    "print(str_series.str.split('i').str.get(-1)) # get the last part after spitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name   info\n",
      "0      vivek  B|C|D\n",
      "1      singh    B|D\n",
      "2       None    B|D\n",
      "3  solanki88  B|C|D \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  C  D\n",
       "0  1  1  1\n",
       "1  1  0  1\n",
       "2  1  0  1\n",
       "3  1  1  1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## if you want to get dummy variables\n",
    "\n",
    "full_monte = pd.DataFrame({'name': str_series,\n",
    "                           'info': ['B|C|D', 'B|D','B|D',  'B|C|D']})\n",
    "print(full_monte,'\\n')\n",
    "\n",
    "full_monte['info'].str.get_dummies('|')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-21 00:00:00\n",
      "Sunday\n",
      "TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None)\n",
      "DatetimeIndex(['2020-06-21', '2020-06-22', '2020-06-23', '2020-06-24',\n",
      "               '2020-06-25'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# to_datetime function can convert many format of strings to date\n",
    "date = pd.to_datetime('21st June, 2020')\n",
    "print(date)\n",
    "print(date.strftime('%A'))\n",
    "\n",
    "# vectorized operations for datetime datetype\n",
    "print(pd.to_timedelta(np.arange(5),'D'))     \n",
    "print(date + pd.to_timedelta(np.arange(5),'D'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-21    0\n",
      "2020-06-22    1\n",
      "2020-06-23    2\n",
      "2020-06-24    3\n",
      "2015-06-25    4\n",
      "dtype: int64\n",
      "2020-06-22    1\n",
      "2020-06-23    2\n",
      "2020-06-24    3\n",
      "dtype: int64\n",
      "\n",
      "2015-06-25    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Pandas Datetime as Index\n",
    "indices = pd.DatetimeIndex(['2020-06-21', '2020-06-22', '2020-06-23', '2020-06-24','2015-06-25'])\n",
    "arr = pd.Series([0,1,2,3,4], index = indices)\n",
    "print(arr)\n",
    "print(arr['2020-06-22': '2020-06-24'])\n",
    "print()\n",
    "print(arr['2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2015-07-04', '2015-07-06', '2015-07-07', '2015-07-08'], dtype='datetime64[ns]', freq=None)\n",
      "TimedeltaIndex(['0 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None)\n",
      "DatetimeIndex(['2013-07-03 12:21:36', '2013-07-05 12:21:36',\n",
      "               '2013-07-06 12:21:36', '2013-07-07 12:21:36'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "dates = pd.to_datetime([ '4th of July, 2015','2015-Jul-6', '07-07-2015', '20150708'])\n",
    "print(dates)\n",
    "\n",
    "print(dates-dates[0])\n",
    "\n",
    "offset = pd.Timedelta(2,'Y')\n",
    "print(dates-offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval function, for efficient operation\n",
    "\n",
    "we have seen that vectorized operation are much faster than the loop version, but what about the memory use?\n",
    "\n",
    "vectorized operations need the arrays in the memory while loop version doesnt need the whole array in the memory, so if the arrays are large enough to not fit or degrade the performance because of computational overhead of vectorized operations then loop version again become handy.\n",
    "\n",
    "so, eval funcntion comes handy here, it takes the expressions as written in vectorized form, but evaluates it using loop version.\n",
    "\n",
    "The Numexpr library gives you the ability to compute this type of compound expression element by element, without the need to allocate full intermediate arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 ms ± 1.05 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "70.5 ms ± 850 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nrows, ncols = 100000, 100\n",
    "rng = np.random.RandomState(42)\n",
    "df1, df2, df3, df4 = (pd.DataFrame(rng.rand(nrows, ncols))\n",
    "                      for i in range(4))\n",
    "\n",
    "\n",
    "%timeit df1 + df2 + df3 + df4\n",
    "\n",
    "%timeit pd.eval('df1 + df2 + df3 + df4') # as we ca se this is taking a way lesser time than the vectorized\n",
    "                                          # version above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
