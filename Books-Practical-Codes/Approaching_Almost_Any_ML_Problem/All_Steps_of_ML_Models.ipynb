{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Author: Vivek Singh Solanki\n",
    "### Book: Approaching Almost Any Machine Learning Problem.\n",
    "### Date: 04-03-2023\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning\n",
    "## Supervised v/s Unsupervised ML\n",
    "  * **Supervised ML:** Learning models where predicting single or multiple variables.\n",
    "    * <b>Classification v/s Regression:</b> Predicting a category v/s a numeric value.\n",
    "  * <b>Un-supervised ML:</b> No target variable, and we need to find patterns or group them.\n",
    "    * __Clustring:__ Instances with no target variable, can be grouped/divided into clusters and helps us to identity patterns. <br> i.e. Credit Card Transactions, where lots of data comes every second, and it gets very difficult to mark them fraud/genuine trx using humans. We can use clustering to group those transactions and find patterns and try to figure out abnormal behaviours.\n",
    "\n",
    "## Cross-Validation\n",
    "* It's a step in process of building ML model for a problem that ensures that the ML model *fits the data accurately* and make sure that it does not *overfit*.\n",
    "* Helps us choose best model from a set of candidate hypotheses.\n",
    "* Helps us find the estimate of performance of the model for production-live version, by mimicking the production live enviornment using the existing data.\n",
    "\n",
    "##### Overfitting:\n",
    "* When a model learns the training data well but fails to generalize unseen samples/ test data. High performance on train-set but very low on test-set.\n",
    "* A hypothesis overfits the training examples, if some other hypothesis that fits the training data less well by performs better on unseen data or over the entire distribution of instances.\n",
    "* High Variance, Low Bias.\n",
    "\n",
    "*Occam's Razor* stats that one should not try to complicate things that can be solved in much simpler manner.\n",
    "**Arises when;**\n",
    "   * We use a complex hypothesis/model for simpler ones.\n",
    "   * When there is noise in the data\n",
    "   * \\# of training examples is too small to produce a representative sample of the true target function.\n",
    "      *\n",
    "\n",
    "##### How Cross-Validation is done?\n",
    "It's simple divide data into two sets, one to train the models and another to test (hold-out/validation/test set) the performance. Though there many methods to cross-validate the models;\n",
    " * __Hold-out:__ above discussed. When data is large and it's expensive to train model several times. time-series data. etc\n",
    " * __k-fold:__ Divide the data randomly into k sets exclusive of each other, use k-1 sets for training and remained one set to test and repeat this k times.\n",
    " * __stratified k-fold:__ when classes are highly imbalanced, dividing randomly could lead no or very less samples for small class, you need to ensure the proportion of that in each of the k sets.\n",
    " * __Leave one out: __\n",
    " * __Group k-fold:__\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
